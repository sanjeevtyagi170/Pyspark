{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff9c1ea",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-19T02:41:04.142031Z",
     "iopub.status.busy": "2022-02-19T02:41:04.141391Z",
     "iopub.status.idle": "2022-02-19T02:41:48.071482Z",
     "shell.execute_reply": "2022-02-19T02:41:48.070840Z"
    },
    "papermill": {
     "duration": 43.951753,
     "end_time": "2022-02-19T02:41:48.071617",
     "exception": false,
     "start_time": "2022-02-19T02:41:04.119864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/netflix-stock-price-data-set-20022022/NFLX.csv\n",
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\r\n",
      "     |████████████████████████████████| 281.4 MB 35 kB/s               \r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: py4j==0.10.9.3 in /opt/conda/lib/python3.7/site-packages (from pyspark) (0.10.9.3)\r\n",
      "Building wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=57195a0e51de97f26114e06aa21042d637d952e1c803b570d57126701688012d\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: pyspark\r\n",
      "Successfully installed pyspark-3.2.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/netflix-stock-price-data-set-20022022/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e989bf77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T02:41:48.343538Z",
     "iopub.status.busy": "2022-02-19T02:41:48.340035Z",
     "iopub.status.idle": "2022-02-19T02:41:48.382455Z",
     "shell.execute_reply": "2022-02-19T02:41:48.382000Z"
    },
    "papermill": {
     "duration": 0.176573,
     "end_time": "2022-02-19T02:41:48.382569",
     "exception": false,
     "start_time": "2022-02-19T02:41:48.205996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012f76fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T02:41:48.658718Z",
     "iopub.status.busy": "2022-02-19T02:41:48.658215Z",
     "iopub.status.idle": "2022-02-19T02:41:53.443751Z",
     "shell.execute_reply": "2022-02-19T02:41:53.443180Z"
    },
    "papermill": {
     "duration": 4.922563,
     "end_time": "2022-02-19T02:41:53.443911",
     "exception": false,
     "start_time": "2022-02-19T02:41:48.521348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/conda/lib/python3.7/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/19 02:41:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc=SparkContext(master=\"local\")\n",
    "spark=SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e01115c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T02:41:53.818718Z",
     "iopub.status.busy": "2022-02-19T02:41:53.818000Z",
     "iopub.status.idle": "2022-02-19T02:41:57.267625Z",
     "shell.execute_reply": "2022-02-19T02:41:57.268449Z"
    },
    "papermill": {
     "duration": 3.641414,
     "end_time": "2022-02-19T02:41:57.268618",
     "exception": false,
     "start_time": "2022-02-19T02:41:53.627204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables() # check whether there are tables in spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "036e763a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T02:41:57.538066Z",
     "iopub.status.busy": "2022-02-19T02:41:57.536941Z",
     "iopub.status.idle": "2022-02-19T02:41:57.952200Z",
     "shell.execute_reply": "2022-02-19T02:41:57.951567Z"
    },
    "papermill": {
     "duration": 0.547657,
     "end_time": "2022-02-19T02:41:57.952329",
     "exception": false,
     "start_time": "2022-02-19T02:41:57.404672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_temp = pd.DataFrame(np.random.random(10)) # this is a pandas dataframe\n",
    "spark_df=spark.createDataFrame(pd_temp) # spark dataframe image created locally \n",
    "spark.catalog.listTables() # as created locally will not find the spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eefa5403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T02:41:58.224717Z",
     "iopub.status.busy": "2022-02-19T02:41:58.223949Z",
     "iopub.status.idle": "2022-02-19T02:41:59.401325Z",
     "shell.execute_reply": "2022-02-19T02:41:59.400813Z"
    },
    "papermill": {
     "duration": 1.315255,
     "end_time": "2022-02-19T02:41:59.401466",
     "exception": false,
     "start_time": "2022-02-19T02:41:58.086211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='random', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.createOrReplaceTempView('random') # created a temp copy from local copy \n",
    "spark.catalog.listTables() # now one can see the spark dataframe in session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d6f59eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T02:41:59.781249Z",
     "iopub.status.busy": "2022-02-19T02:41:59.780443Z",
     "iopub.status.idle": "2022-02-19T02:42:00.651162Z",
     "shell.execute_reply": "2022-02-19T02:42:00.651559Z"
    },
    "papermill": {
     "duration": 1.063661,
     "end_time": "2022-02-19T02:42:00.651703",
     "exception": false,
     "start_time": "2022-02-19T02:41:59.588042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sql_spark=spark.sql(\"select * from random\") # using spark.sql to fetch results from spark dataframe\n",
    "df_pandas=df_sql_spark.toPandas() # spark dataframe converted to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bedc4f27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T02:42:00.919789Z",
     "iopub.status.busy": "2022-02-19T02:42:00.919280Z",
     "iopub.status.idle": "2022-02-19T02:42:02.087582Z",
     "shell.execute_reply": "2022-02-19T02:42:02.087011Z"
    },
    "papermill": {
     "duration": 1.304655,
     "end_time": "2022-02-19T02:42:02.087759",
     "exception": false,
     "start_time": "2022-02-19T02:42:00.783104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+--------+--------+---------+---------+\n",
      "|      Date|    Open|    High|     Low|   Close|Adj Close|   Volume|\n",
      "+----------+--------+--------+--------+--------+---------+---------+\n",
      "|2002-05-23|1.156429|1.242857|1.145714|1.196429| 1.196429|104790000|\n",
      "|2002-05-24|1.214286|1.225000|1.197143|1.210000| 1.210000| 11104800|\n",
      "+----------+--------+--------+--------+--------+---------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# directly importing csv file into spark\n",
    "path=\"/kaggle/input/netflix-stock-price-data-set-20022022/NFLX.csv\"\n",
    "netf=spark.read.csv(path,header=True)\n",
    "netf.show(2)\n",
    "netf.createOrReplaceTempView(\"netf\") # creating from local copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d96318f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T02:42:02.359043Z",
     "iopub.status.busy": "2022-02-19T02:42:02.358371Z",
     "iopub.status.idle": "2022-02-19T02:42:02.664459Z",
     "shell.execute_reply": "2022-02-19T02:42:02.663580Z"
    },
    "papermill": {
     "duration": 0.441314,
     "end_time": "2022-02-19T02:42:02.664663",
     "exception": false,
     "start_time": "2022-02-19T02:42:02.223349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+--------+--------+---------+---------+-------+\n",
      "|      Date|    Open|    High|     Low|   Close|Adj Close|   Volume|  volmn|\n",
      "+----------+--------+--------+--------+--------+---------+---------+-------+\n",
      "|2002-05-23|1.156429|1.242857|1.145714|1.196429| 1.196429|104790000| 104.79|\n",
      "|2002-05-24|1.214286|1.225000|1.197143|1.210000| 1.210000| 11104800|11.1048|\n",
      "|2002-05-28|1.213571|1.232143|1.157143|1.157143| 1.157143|  6609400| 6.6094|\n",
      "+----------+--------+--------+--------+--------+---------+---------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "netf_df=spark.table(\"netf\")\n",
    "netf_df=netf_df.withColumn('volmn',netf_df.Volume/1000000)\n",
    "netf_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c0c182a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T02:42:03.013125Z",
     "iopub.status.busy": "2022-02-19T02:42:03.012120Z",
     "iopub.status.idle": "2022-02-19T02:42:03.030365Z",
     "shell.execute_reply": "2022-02-19T02:42:03.030973Z"
    },
    "papermill": {
     "duration": 0.228729,
     "end_time": "2022-02-19T02:42:03.031141",
     "exception": false,
     "start_time": "2022-02-19T02:42:02.802412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Date: string, Open: string, High: string, Low: string, Close: string, Adj Close: string, Volume: string, volmn: double]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering data\n",
    "netf_df.filter(netf_df.Low>4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8606280c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T02:42:03.415099Z",
     "iopub.status.busy": "2022-02-19T02:42:03.414538Z",
     "iopub.status.idle": "2022-02-19T02:42:03.432220Z",
     "shell.execute_reply": "2022-02-19T02:42:03.432860Z"
    },
    "papermill": {
     "duration": 0.210961,
     "end_time": "2022-02-19T02:42:03.433034",
     "exception": false,
     "start_time": "2022-02-19T02:42:03.222073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Low: string, Close: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting data\n",
    "netf_df.select(netf_df.Low,netf_df.Close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b51d41e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T02:42:03.706222Z",
     "iopub.status.busy": "2022-02-19T02:42:03.705647Z",
     "iopub.status.idle": "2022-02-19T02:42:03.708982Z",
     "shell.execute_reply": "2022-02-19T02:42:03.709427Z"
    },
    "papermill": {
     "duration": 0.139407,
     "end_time": "2022-02-19T02:42:03.709575",
     "exception": false,
     "start_time": "2022-02-19T02:42:03.570168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#aggregating data\n",
    "#netf_df.select(netf_df.Low,netf_df.Close,netf_df.volmn>10).filter(netf_df.Close>10).groupBy().sum(\"volmn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f10f4",
   "metadata": {
    "papermill": {
     "duration": 0.130508,
     "end_time": "2022-02-19T02:42:03.971387",
     "exception": false,
     "start_time": "2022-02-19T02:42:03.840879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 69.641206,
   "end_time": "2022-02-19T02:42:04.819427",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-19T02:40:55.178221",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
